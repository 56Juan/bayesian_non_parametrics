{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21b5637",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cee198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports y configuración\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Agregar el directorio raíz al path\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), '..'))\n",
    "\n",
    "# Imports del proyecto\n",
    "from model_ddp.utils.sistem_fun import (\n",
    "    load_config,\n",
    "    get_data_path,\n",
    "    get_artifact_path,\n",
    "    get_report_path,\n",
    "    create_experiment_id,\n",
    "    ensure_directories\n",
    ")\n",
    "\n",
    "from model_ddp.simulations.gaussian_simulator import (\n",
    "    RegressionSimulator,\n",
    "    SimulationConfig,\n",
    "    RBFKernel,\n",
    "    MaternKernel,\n",
    "    PeriodicKernel,\n",
    "    TransformationFunctions\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "from model_ddp.models.LSBP_normal_v1 import LSBPNormal\n",
    "\n",
    "# Metricas\n",
    "from model_ddp.fit.metrics import regression_metrics\n",
    "\n",
    "config=load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a5c2d",
   "metadata": {},
   "source": [
    "# Flujo \n",
    "\n",
    "- Datos: Se guardaran todo en una carpeta. Por tanto todo tratamiento debe ir previo a un experimento.\n",
    "- Experimentos: Cada modelo quedara en una carpeta con id, por tanto se crean versiones para cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros Iniciales\n",
    "NOMBRE_EJECUCION = \"model_lsbp_001\"\n",
    "SIM_REAL = \"simulation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Crear carpeta de guardado \n",
    "##################################################\n",
    "data_path = get_data_path(config, SIM_REAL, \"output\")\n",
    "carpeta_datos = data_path / f\"{NOMBRE_EJECUCION}\"\n",
    "carpeta_datos.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "##################################################\n",
    "# Simulacion o data real\n",
    "##################################################\n",
    "# Configuración de la simulación\n",
    "sim_config = SimulationConfig(\n",
    "    n_samples=50,\n",
    "    n_features=5,\n",
    "    x_range=(0.0, 10.0),\n",
    "    noise_std=0.3,\n",
    "    random_state=234\n",
    ")\n",
    "\n",
    "# Definir kernel (RBF)\n",
    "kernel = RBFKernel(\n",
    "    length_scale=2.0,\n",
    "    variance=1.0\n",
    ")\n",
    "\n",
    "# Definir transformación (regresión lineal)\n",
    "coefficients = np.array([2.5, -1.8, 0.9, 1.2, -0.5])\n",
    "intercept = 3.0\n",
    "\n",
    "transformation = TransformationFunctions.linear(\n",
    "    coefficients=coefficients,\n",
    "    intercept=intercept\n",
    ")\n",
    "\n",
    "# Crear simulador\n",
    "simulator = RegressionSimulator(\n",
    "    config=sim_config,\n",
    "    kernel=kernel,\n",
    "    transformation=transformation\n",
    ")\n",
    "\n",
    "# Generar datos\n",
    "print(\"Generando datos...\")\n",
    "X, Y = simulator.simulate()\n",
    "\n",
    "print(\"✓ Datos generados exitosamente\")\n",
    "print(f\"\\nEstadísticas de X:\")\n",
    "print(f\"  Shape: {X.shape}\")\n",
    "print(f\"  Media por feature: {X.mean(axis=0)}\")\n",
    "print(f\"  Std por feature: {X.std(axis=0)}\")\n",
    "print(f\"\\nEstadísticas de Y:\")\n",
    "print(f\"  Shape: {Y.shape}\")\n",
    "print(f\"  Media: {Y.mean():.4f}\")\n",
    "print(f\"  Std: {Y.std():.4f}\")\n",
    "print(f\"  Min: {Y.min():.4f}\")\n",
    "print(f\"  Max: {Y.max():.4f}\")\n",
    "\n",
    "##################################################\n",
    "# Transformar a data frame \n",
    "##################################################\n",
    "datos = pd.DataFrame(X, columns=[f'X{i+1}' for i in range(sim_config.n_features)])\n",
    "datos['Y'] = Y\n",
    "\n",
    "##################################################\n",
    "# Guardar data frame  \n",
    "##################################################\n",
    "csv_filename = f\"{carpeta_datos}/_data.csv\"\n",
    "datos.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"✓ Datos guardados en CSV: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108fc1b",
   "metadata": {},
   "source": [
    "## Experimento I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb164aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de ejecución\n",
    "CARACTERISTICAS = \"Test inicial: GP con kernel RBF + transformación lineal\"\n",
    "EXPERIMENT_ID = create_experiment_id(\"lsbp_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Modelo   \n",
    "##################################################\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EJECUTANDO LSBPNormal...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear instancia del modelo\n",
    "lsbp_model = LSBPNormal(\n",
    "    y=datos[\"Y\"].values,\n",
    "    X=datos.drop(columns=[\"Y\"]).values,\n",
    "    H=15,                     # Número inicial de clusters truncados\n",
    "    verbose=True              # Mostrar progreso\n",
    ")\n",
    "\n",
    "# Ejecutar MCMC\n",
    "trace = lsbp_model.run(\n",
    "    iterations=50,          # Iteraciones totales\n",
    "    burnin=10               # Burn-in\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LSBP COMPLETADO\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54395cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#  Guardar Modelo  (SEGUN EXPERIMENTO)\n",
    "##################################################\n",
    "\n",
    "# Crear carpetas para guardar\n",
    "artifact_path = get_artifact_path(config, SIM_REAL)\n",
    "carpeta_modelo = artifact_path / f\"{EXPERIMENT_ID}\"\n",
    "carpeta_modelo.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GUARDANDO MODELO Y RESULTADOS...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Guardar el modelo completo (objeto LSBPNormal)\n",
    "model_file = carpeta_modelo / \"lsbp_model.pkl\"\n",
    "with open(model_file, 'wb') as f:\n",
    "    pickle.dump(lsbp_model, f)\n",
    "print(f\"✓ Modelo guardado: {model_file}\")\n",
    "\n",
    "# 2. Guardar solo las trazas (más ligero)\n",
    "trace_file = carpeta_modelo / \"trace.pkl\"\n",
    "with open(trace_file, 'wb') as f:\n",
    "    pickle.dump(trace, f)\n",
    "print(f\"✓ Trazas guardadas: {trace_file}\")\n",
    "\n",
    "# 3. Guardar resumen posterior\n",
    "summary = lsbp_model.get_posterior_summary()\n",
    "summary_file = carpeta_modelo / \"posterior_summary.json\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    # Convertir tuplas a listas para JSON\n",
    "    summary_json = {k: {'mean': v[0], 'std': v[1]} for k, v in summary.items()}\n",
    "    json.dump(summary_json, f, indent=2)\n",
    "print(f\"✓ Resumen posterior guardado: {summary_file}\")\n",
    "\n",
    "# 4. Guardar metadatos del experimento\n",
    "metadata = {\n",
    "    'experiment_id': EXPERIMENT_ID,\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'model_type': 'LSBPNormal',\n",
    "    'data_shape': {\n",
    "        'n': lsbp_model.n,\n",
    "        'p': lsbp_model.p\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'H_initial': 15,\n",
    "        'iterations': 50,\n",
    "        'burnin': 10,\n",
    "        'n_grid': lsbp_model.n_grid\n",
    "    },\n",
    "    'priors': {\n",
    "        'mu_prior': (lsbp_model.mu_mu, lsbp_model.tau_mu_inv),\n",
    "        'mu0_prior': (lsbp_model.m0, lsbp_model.s02),\n",
    "        'kappa0_prior': (lsbp_model.alpha_kappa, lsbp_model.beta_kappa),\n",
    "        'a0_prior': (lsbp_model.alpha_a, lsbp_model.beta_a),\n",
    "        'b0_prior': (lsbp_model.alpha_b, lsbp_model.beta_b),\n",
    "        'psi_prior': (lsbp_model.mu_psi, lsbp_model.tau_psi_inv)\n",
    "    },\n",
    "    'final_stats': {\n",
    "        'H_final': lsbp_model.H,\n",
    "        'n_clusters_mean': summary['n_clusters'][0],\n",
    "        'n_clusters_std': summary['n_clusters'][1]\n",
    "    },\n",
    "    'acceptance_rates': {\n",
    "        'alpha': np.mean(lsbp_model.mh_acceptance['alpha'][-100:]) if lsbp_model.mh_acceptance['alpha'] else 0,\n",
    "        'psi': np.mean(lsbp_model.mh_acceptance['psi'][-100:]) if lsbp_model.mh_acceptance['psi'] else 0,\n",
    "        'kappa0': np.mean(lsbp_model.mh_acceptance['kappa0'][-100:]) if lsbp_model.mh_acceptance['kappa0'] else 0,\n",
    "        'a0': np.mean(lsbp_model.mh_acceptance['a0'][-100:]) if lsbp_model.mh_acceptance['a0'] else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_file = carpeta_modelo / \"metadata.json\"\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"✓ Metadatos guardados: {metadata_file}\")\n",
    "\n",
    "# 5. Guardar información de normalización \n",
    "normalization_file = carpeta_modelo / \"normalization.pkl\"\n",
    "normalization_data = {\n",
    "    'y_mean': lsbp_model.y_mean,\n",
    "    'y_std': lsbp_model.y_std,\n",
    "    'X_mean': lsbp_model.X_mean,\n",
    "    'X_std': lsbp_model.X_std\n",
    "}\n",
    "with open(normalization_file, 'wb') as f:\n",
    "    pickle.dump(normalization_data, f)\n",
    "print(f\"✓ Datos de normalización guardados: {normalization_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"MODELO GUARDADO EN: {carpeta_modelo}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Graficas y FIT  (SEGUN EXPERIMENTO)\n",
    "##################################################\n",
    "# FALTA ESTO\n",
    "\n",
    "metrics = regression_metrics(y_true, y_pred)\n",
    "\n",
    "print(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Reguistrar exprimento \n",
    "##################################################\n",
    "\n",
    "# Y ESTO "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
